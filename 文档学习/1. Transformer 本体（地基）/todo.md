ğŸ§± ç¬¬ä¸€é˜¶æ®µï¼šTransformer æœ¬ä½“ï¼ˆåœ°åŸºï¼‰
1ï¸âƒ£ Attention Is All You Needï¼ˆ2017ï¼‰âœ…

é˜…è¯»é¡ºåº

ç¬¬ 1 é¡µï¼ˆIntroductionï¼‰âœ…

ç¬¬ 3 é¡µï¼ˆModel Architectureï¼‰âœ…

ç¬¬ 4 é¡µï¼ˆAttention å…¬å¼ + å›¾ï¼‰âœ…

ç¬¬ 5 é¡µï¼ˆPosition Encodingï¼‰âš ï¸ï¼ˆçœ‹æ€æƒ³å³å¯ï¼‰

ç¬¬ 6 é¡µï¼ˆTrainingï¼‰âš ï¸

é‡ç‚¹çœ‹ä»€ä¹ˆ

å›¾ 1ï¼ˆæ•´ä½“ç»“æ„ï¼‰

Scaled Dot-Product Attention

Multi-Head Attention ä¸ºä»€ä¹ˆè¦å¤šå¤´

å¯ä»¥è·³è¿‡

BLEU åˆ†æ•°

è¶…å‚æ•°ç»†èŠ‚

ğŸ¯ è¯»å®Œä½ åº”è¯¥èƒ½å›ç­”

Transformer ä¸ºä»€ä¹ˆä¸éœ€è¦ RNNï¼Ÿ

2ï¸âƒ£ The Illustrated Transformerï¼ˆåšå®¢ï¼‰âœ…

å…¨æ–‡é¡ºè¯»

æŠŠè®ºæ–‡ä¸­çš„ç¬¦å·â€œç¿»è¯‘æˆäººè¯â€

ğŸ¯ ç›®æ ‡

èƒ½åœ¨è„‘ä¸­è·‘ä¸€é forward æµç¨‹


---

---
## ğŸ“š è®ºæ–‡é“¾æ¥ (Paper Links)

| Paper | Abstract | PDF |
|---|---|---|
| Attention Is All You Need | [Abstract](https://arxiv.org/abs/1706.03762) | [PDF](https://arxiv.org/pdf/1706.03762.pdf) |