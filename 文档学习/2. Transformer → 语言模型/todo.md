ğŸ§¬ ç¬¬äºŒé˜¶æ®µï¼šTransformer â†’ è¯­è¨€æ¨¡å‹
3ï¸âƒ£ GPT-1: Improving Language Understandingâ€¦ï¼ˆ2018ï¼‰âœ…

é˜…è¯»é¡ºåº

ç¬¬ 1 é¡µï¼ˆMotivationï¼‰âœ…

ç¬¬ 2 é¡µï¼ˆLanguage Model Pre-trainingï¼‰âœ…

Figure 1ï¼ˆPretrain â†’ Finetuneï¼‰âœ…

å®éªŒéƒ¨åˆ† âš ï¸

é‡ç‚¹

Decoder-only

è‡ªå›å½’å»ºæ¨¡

ä¸ºä»€ä¹ˆ finetune å°‘é‡æ•°æ®å°±æœ‰æ•ˆ

ğŸ¯ ç›®æ ‡

æ˜ç™½â€œè¯­è¨€æ¨¡å‹â€æœ¬èº«å°±æ˜¯ä¸€ä¸ªé€šç”¨ç‰¹å¾æå–å™¨

4ï¸âƒ£ GPT-2: Language Models are Unsupervisedâ€¦ï¼ˆ2019ï¼‰âœ…

é˜…è¯»é¡ºåº

Abstract

ç¬¬ 1 é¡µï¼ˆZero-shotï¼‰

Figure 2ï¼ˆPrompt ç¤ºä¾‹ï¼‰âœ…

å…¶ä½™å®éªŒ âš ï¸

é‡ç‚¹

Prompt = è¾“å…¥çš„ä¸€éƒ¨åˆ†

ä¸å†æ˜¾å¼ finetune

ğŸ¯ ç›®æ ‡

ç†è§£ Prompt Learning çš„èµ·ç‚¹


---

---
## ğŸ“š è®ºæ–‡é“¾æ¥ (Paper Links)

| Paper | Abstract | PDF |
|---|---|---|
| GPT-1: Improving Language Understanding... | - | [PDF](https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf) |
| GPT-2: Language Models are Unsupervised Multitask Learners | [Abstract](https://arxiv.org/abs/1901.11373) | [PDF](https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf) |